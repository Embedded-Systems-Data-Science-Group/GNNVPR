{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(path, r_string, type_string, timing=False):\n",
    "    all_files = glob.glob(os.path.join(path, \"*\"+r_string+type_string+\"*.csv\"))\n",
    "    for file in all_files:\n",
    "        if os.path.getsize(file) == 0:\n",
    "            all_files.remove(file)\n",
    "    # print(\"Running Metric\")\n",
    "    print(type(all_files))\n",
    "    results = dict()\n",
    "    results[type_string] = dict()\n",
    "    results['reg'] = dict()\n",
    "    results['time_'+type_string] = dict()\n",
    "    results['time_reg'] = dict()\n",
    "    results['CPD_'+type_string] = dict()\n",
    "    results['CPD_REG'] = dict()\n",
    "    # results['minw'] = dict()\n",
    "    # results['minw_REG'] = dict()\n",
    "    gnn_results = dict()\n",
    "    reg_results = dict()\n",
    "    for gnn_metric in all_files:\n",
    "        lf = gnn_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__\"+type_string+\"__\")[0]\n",
    "        # print(name)\n",
    "    \n",
    "        df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "        max_key = df.tail(1).index.values[0]\n",
    "        # print(df['Iteration'])\n",
    "        # print(\"Test\" , df['Iteration'][max_key])  \n",
    "        gnn_results[name] = int(df['Iteration'][max_key])\n",
    "        # print(df[].head())\n",
    "    results[type_string] = gnn_results\n",
    "    reg_results = dict()\n",
    "    for gnn_metric in all_files:\n",
    "        lf = gnn_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__\"+type_string+\"__\")[0]\n",
    "        # print(name)\n",
    "        df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "       \n",
    "        reg_results[name] = sum(df['Time'])\n",
    "    results['time_'+type_string] = reg_results\n",
    "    # print(results)\n",
    "    reg_results = dict()\n",
    "\n",
    "    reg_results = dict()\n",
    "    for gnn_metric in all_files:\n",
    "        lf = gnn_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__\"+type_string+\"__\")[0]\n",
    "        # print(name)\n",
    "        df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "       \n",
    "        reg_results[name] = max(df['CPD (ns)'])\n",
    "    results['CPD_'+type_string] = reg_results\n",
    "    # print(results)\n",
    "    reg_results = dict()\n",
    "    all_files = glob.glob(os.path.join(path, r_string+\"*reg*.csv\"))\n",
    "    for file in all_files:\n",
    "        if os.path.getsize(file) == 0:\n",
    "            all_files.remove(file)\n",
    "    for reg_metric in all_files:\n",
    "        lf = reg_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__reg__\")[0]\n",
    "        # print(name)\n",
    "        df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "\n",
    "        max_key = df.tail(1).index.values[0]\n",
    "        reg_results[name] = df['Iteration'][max_key]\n",
    "        # print(df[].head())  \n",
    "    results['reg'] = reg_results\n",
    "\n",
    "    reg_results = dict()\n",
    "    for reg_metric in all_files:\n",
    "        lf = reg_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__reg__\")[0]\n",
    "        # print(name)\n",
    "        df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "        reg_results[name] = sum(df['Time'])\n",
    "    results['time_reg'] = reg_results\n",
    "\n",
    "    reg_results = dict()\n",
    "    for reg_metric in all_files:\n",
    "        lf = reg_metric.split(\"/\")[-1]\n",
    "        lf = lf.split(\".\")[0]\n",
    "        name = lf.split(\"__reg__\")[0]\n",
    "        # print(name)\n",
    "        df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "        reg_results[name] = max(df['CPD (ns)'])\n",
    "    results['CPD_REG'] = reg_results\n",
    "        # print(df[].head())\n",
    "\n",
    "    # print(results)\n",
    "    my_df = pd.DataFrame.from_dict(results)\n",
    "    # my_df = my_df.drop(\"EArch__des\")\n",
    "    # print(my_df)\n",
    "\n",
    "    values1 = list(my_df['reg'].values)\n",
    "    values2 = list(my_df[type_string].values)\n",
    "    reduction = list()\n",
    "    for i in range(len(values1)):\n",
    "        if values1[i] == -1 or values2[i] == -1:\n",
    "            reduction.append(0)\n",
    "        else:\n",
    "            reduction.append((values1[i]- values2[i]) /values1[i])\n",
    "    my_df['Reduction'] = reduction\n",
    "    # my_df['Reduction'] = [(i - j / i) for i, j in zip(values1, values2)]\n",
    "    # my_df['Reduction'] = (my_df['reg'].values - my_df[type_string].values)/my_df['reg'].values\n",
    "    # my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "\n",
    "    # print(\"{:2%}\".format(my_df))\n",
    "    my_df.dropna(inplace=True)\n",
    "    # my_df = my_df.drop(\"EArch__des\")\n",
    "    print(\"Average: \", \"{:.2%}\".format(mean(my_df['Reduction'].values)))\n",
    "\n",
    "    pd.set_option('expand_frame_repr', False)\n",
    "    my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "    my_df['time_reg']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_reg']], index = my_df.index)\n",
    "    my_df['time_'+type_string]=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_'+type_string]], index = my_df.index)\n",
    "    my_df['CPD_REG']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_REG']], index = my_df.index)\n",
    "    my_df['CPD_'+type_string]=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_'+type_string]], index = my_df.index)\n",
    "    \n",
    "    print(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Average:  5.34%\n",
      "                 gnn  reg time_gnn time_reg CPD_gnn CPD_REG Reduction\n",
      "EArch__alu4       12   -1     3.76     0.19    6.15    6.18     0.00%\n",
      "EArch__apex2      27   -1     4.11     0.35    6.37    6.38     0.00%\n",
      "EArch__apex4      -1   -1     5.47     0.33    6.12    5.97     0.00%\n",
      "EArch__bigkey      9   14     5.33     0.18    2.68    2.49    35.71%\n",
      "EArch__clma       24   -1     8.75     1.02   12.60   12.46     0.00%\n",
      "EArch__des        -1   -1     5.87     0.38    5.46    5.99     0.00%\n",
      "EArch__diffeq      9   12     4.39     0.15    6.55    6.55    25.00%\n",
      "EArch__dsip       12   -1     3.69     0.46    3.05    3.12     0.00%\n",
      "EArch__elliptic   11   -1     6.06     0.37    8.72    8.73     0.00%\n",
      "EArch__ex1010     14   -1     5.48     0.50    8.06    8.06     0.00%\n",
      "EArch__ex5p       28   -1     3.77     0.19    5.83    5.70     0.00%\n",
      "EArch__frisc      21   -1     5.14     0.47   12.83   12.83     0.00%\n",
      "EArch__misex3    131   -1     7.65     0.29    6.31    5.71     0.00%\n",
      "EArch__pdc        24   -1     6.98     0.95    8.82    8.82     0.00%\n",
      "EArch__s298        7   13     3.56     0.16   11.17   11.16    46.15%\n",
      "EArch__s38417     20   -1     7.32     0.37    7.89    7.90     0.00%\n",
      "EArch__s38584     25   -1     8.33     0.37    6.42    6.56     0.00%\n",
      "EArch__seq        -1   -1     5.82     0.40    6.08    5.80     0.00%\n",
      "EArch__spla       24   -1     7.35     0.56    7.89    7.91     0.00%\n",
      "EArch__tseng       8   -1     4.10     0.15    6.96    6.96     0.00%\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/e/benchmarks/route_metrics/MCNC/\"\n",
    "r_string = \"EArch*\"\n",
    "type_string = \"gnn\"\n",
    "metric(path, r_string, type_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Average:  -36.33%\n",
      "                            gnn  reg time_gnn time_reg CPD_gnn CPD_REG Reduction\n",
      "stratixiv_arch__alu4       51.0   31     7.40     1.95   10.57   10.16   -64.52%\n",
      "stratixiv_arch__apex2      -1.0   47     6.21     4.54   10.66   10.67     0.00%\n",
      "stratixiv_arch__apex4      98.0   45    16.25     4.55   10.17   10.57  -117.78%\n",
      "stratixiv_arch__bigkey      4.0    4    21.16     0.17    7.87    7.78     0.00%\n",
      "stratixiv_arch__clma       -1.0   -1    19.93    21.79   10.30    9.98     0.00%\n",
      "stratixiv_arch__des        12.0  102    28.73    25.85   12.43   12.43    88.24%\n",
      "stratixiv_arch__diffeq     53.0   40    12.34     4.11    7.53    7.54   -32.50%\n",
      "stratixiv_arch__dsip      100.0   19    24.19     0.82    7.52    7.52  -426.32%\n",
      "stratixiv_arch__elliptic   47.0   40   221.43   140.31   10.28    9.76   -17.50%\n",
      "stratixiv_arch__ex1010     87.0   62    37.13    17.02   13.09   13.13   -40.32%\n",
      "stratixiv_arch__ex5p      145.0   63    36.11     8.56   10.85   10.49  -130.16%\n",
      "stratixiv_arch__frisc      -1.0   -1    39.95    42.31   11.98   12.02     0.00%\n",
      "stratixiv_arch__misex3     -1.0   58     9.37     4.84    9.37   10.04     0.00%\n",
      "stratixiv_arch__pdc       150.0  203    56.46   130.88   12.10   12.83    26.11%\n",
      "stratixiv_arch__s298        6.0   50     9.97     1.02    9.14    9.82    88.00%\n",
      "stratixiv_arch__s38417     11.0   35    11.63    16.96    8.04    8.35    68.57%\n",
      "stratixiv_arch__s38584     -1.0   -1    14.12     6.02   11.36   10.72     0.00%\n",
      "stratixiv_arch__seq       145.0   77    20.89    10.91    9.70    9.79   -88.31%\n",
      "stratixiv_arch__spla      194.0  111    36.55    39.57   11.20   11.78   -74.77%\n",
      "stratixiv_arch__tseng      20.0   19     3.20     0.46    6.87    6.90    -5.26%\n"
     ]
    }
   ],
   "source": [
    "path = \"/mnt/e/benchmarks/route_metrics/TITAN/\"\n",
    "r_string = \"strat*\"\n",
    "type_string = \"gnn\"\n",
    "metric(path, r_string, type_string)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33523b78cfab29329be06c8dc9e0bc68c55f5871a327f9619ac45fb3b56bad04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cs235')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
