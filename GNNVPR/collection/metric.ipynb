{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from statistics import mean\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "path = \"/mnt/e/benchmarks/Outputs/route_metrics/EARCH_MCNC/\"\n",
    "all_files = glob.glob(os.path.join(path, \"EArch*gnn*.csv\"))\n",
    "results = dict()\n",
    "results['gnn'] = dict()\n",
    "results['reg'] = dict()\n",
    "gnn_results = dict()\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    gnn_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['gnn'] = gnn_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "all_files = glob.glob(os.path.join(path, \"EArch*reg*.csv\"))\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['reg'] = reg_results\n",
    "\n",
    "# print(results)\n",
    "my_df = pd.DataFrame.from_dict(results)\n",
    "# print(my_df)\n",
    "\n",
    "my_df['Reduction'] = (my_df['reg'].values - my_df['gnn'].values)/my_df['reg'].values\n",
    "print(\"Average: \", \"{:.2%}\".format(mean(my_df['Reduction'].values)))\n",
    "\n",
    "my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "\n",
    "print(my_df)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "path = \"/mnt/e/benchmarks/Outputs/route_metrics/\"\n",
    "r_string = \"strat\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, r_string+\"*gnn*.csv\"))\n",
    "results = dict()\n",
    "results['gnn'] = dict()\n",
    "results['reg'] = dict()\n",
    "results['time_gnn'] = dict()\n",
    "results['time_reg'] = dict()\n",
    "results['CPD_GNN'] = dict()\n",
    "results['CPD_REG'] = dict()\n",
    "gnn_results = dict()\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    gnn_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['gnn'] = gnn_results\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = sum(df['Time'])\n",
    "results['time_gnn'] = reg_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['CPD (ns)'])\n",
    "results['CPD_GNN'] = reg_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "all_files = glob.glob(os.path.join(path, r_string+\"*reg*.csv\"))\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())  \n",
    "results['reg'] = reg_results\n",
    "\n",
    "reg_results = dict()\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = sum(df['Time'])\n",
    "results['time_reg'] = reg_results\n",
    "\n",
    "reg_results = dict()\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['CPD (ns)'])\n",
    "results['CPD_REG'] = reg_results\n",
    "    # print(df[].head())\n",
    "\n",
    "# print(results)\n",
    "my_df = pd.DataFrame.from_dict(results)\n",
    "# print(my_df)\n",
    "my_df['Reduction'] = (my_df['reg'].values - my_df['gnn'].values)/my_df['reg'].values\n",
    "# my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "\n",
    "print(\"Average: \", \"{:.2%}\".format(mean(my_df['Reduction'].values)))\n",
    "# print(\"{:2%}\".format(my_df))\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "my_df['time_reg']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_reg']], index = my_df.index)\n",
    "my_df['time_gnn']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_gnn']], index = my_df.index)\n",
    "my_df['CPD_REG']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_REG']], index = my_df.index)\n",
    "my_df['CPD_GNN']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_GNN']], index = my_df.index)\n",
    "print(my_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average:  14.94%\n",
      "                 gnn  reg time_gnn time_reg CPD_GNN CPD_REG Reduction\n",
      "EArch__alu4       13   14    11.05     0.26    5.54    5.50     7.14%\n",
      "EArch__apex2      12   15    10.88     0.38    6.30    6.30    20.00%\n",
      "EArch__apex4      13   15     9.93     0.28    5.25    5.25    13.33%\n",
      "EArch__bigkey      9   11    12.07     0.24    2.64    2.64    18.18%\n",
      "EArch__clma       13   15    35.36     1.60   11.32   11.31    13.33%\n",
      "EArch__des        11   13    16.91     0.42    5.20    5.20    15.38%\n",
      "EArch__diffeq     11   14    12.06     0.26    6.44    6.44    21.43%\n",
      "EArch__dsip        9   12    12.60     0.23    2.63    2.63    25.00%\n",
      "EArch__elliptic   12   13    15.39     0.54    9.06    9.06     7.69%\n",
      "EArch__ex1010     14   16    17.91     0.86    7.37    7.44    12.50%\n",
      "EArch__ex5p       12   16    10.30     0.21    5.36    5.36    25.00%\n",
      "EArch__frisc      12   13    18.62     0.59   11.83   11.84     7.69%\n",
      "EArch__misex3     13   15     9.68     0.25    5.15    5.16    13.33%\n",
      "EArch__pdc        14   17    20.25     1.37    7.96    8.09    17.65%\n",
      "EArch__s298       11   14    10.50     0.25   10.05   10.05    21.43%\n",
      "EArch__s38417     13   14    22.22     1.09    7.37    7.36     7.14%\n",
      "EArch__s38584     10   12    21.82     0.73    6.53    6.53    16.67%\n",
      "EArch__seq        12   14    10.81     0.33    5.23    5.23    14.29%\n",
      "EArch__spla       14   16    20.40     1.09    6.94    6.94    12.50%\n",
      "EArch__tseng      10   11    11.53     0.14    6.52    6.52     9.09%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "path = \"/mnt/e/benchmarks/Outputs/route_metrics/EARCH_MCNC/\"\n",
    "r_string = \"EArch\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, r_string+\"*gnn*.csv\"))\n",
    "results = dict()\n",
    "results['gnn'] = dict()\n",
    "results['reg'] = dict()\n",
    "results['time_gnn'] = dict()\n",
    "results['time_reg'] = dict()\n",
    "results['CPD_GNN'] = dict()\n",
    "results['CPD_REG'] = dict()\n",
    "gnn_results = dict()\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    gnn_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['gnn'] = gnn_results\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = sum(df['Time'])\n",
    "results['time_gnn'] = reg_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['CPD (ns)'])\n",
    "results['CPD_GNN'] = reg_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "all_files = glob.glob(os.path.join(path, r_string+\"*reg*.csv\"))\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())  \n",
    "results['reg'] = reg_results\n",
    "\n",
    "reg_results = dict()\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = sum(df['Time'])\n",
    "results['time_reg'] = reg_results\n",
    "\n",
    "reg_results = dict()\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['CPD (ns)'])\n",
    "results['CPD_REG'] = reg_results\n",
    "    # print(df[].head())\n",
    "\n",
    "# print(results)\n",
    "my_df = pd.DataFrame.from_dict(results)\n",
    "# print(my_df)\n",
    "my_df['Reduction'] = (my_df['reg'].values - my_df['gnn'].values)/my_df['reg'].values\n",
    "# my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "\n",
    "print(\"Average: \", \"{:.2%}\".format(mean(my_df['Reduction'].values)))\n",
    "# print(\"{:2%}\".format(my_df))\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "my_df['time_reg']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_reg']], index = my_df.index)\n",
    "my_df['time_gnn']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['time_gnn']], index = my_df.index)\n",
    "my_df['CPD_REG']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_REG']], index = my_df.index)\n",
    "my_df['CPD_GNN']=  pd.Series([\"{0:.2f}\".format(val) for val in my_df['CPD_GNN']], index = my_df.index)\n",
    "print(my_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average:  14.94%\n",
      "                 gnn  reg time_gnn time_reg CPD_GNN CPD_REG Reduction\n",
      "EArch__alu4       13   14    11.05     0.26    5.54    5.50     7.14%\n",
      "EArch__apex2      12   15    10.88     0.38    6.30    6.30    20.00%\n",
      "EArch__apex4      13   15     9.93     0.28    5.25    5.25    13.33%\n",
      "EArch__bigkey      9   11    12.07     0.24    2.64    2.64    18.18%\n",
      "EArch__clma       13   15    35.36     1.60   11.32   11.31    13.33%\n",
      "EArch__des        11   13    16.91     0.42    5.20    5.20    15.38%\n",
      "EArch__diffeq     11   14    12.06     0.26    6.44    6.44    21.43%\n",
      "EArch__dsip        9   12    12.60     0.23    2.63    2.63    25.00%\n",
      "EArch__elliptic   12   13    15.39     0.54    9.06    9.06     7.69%\n",
      "EArch__ex1010     14   16    17.91     0.86    7.37    7.44    12.50%\n",
      "EArch__ex5p       12   16    10.30     0.21    5.36    5.36    25.00%\n",
      "EArch__frisc      12   13    18.62     0.59   11.83   11.84     7.69%\n",
      "EArch__misex3     13   15     9.68     0.25    5.15    5.16    13.33%\n",
      "EArch__pdc        14   17    20.25     1.37    7.96    8.09    17.65%\n",
      "EArch__s298       11   14    10.50     0.25   10.05   10.05    21.43%\n",
      "EArch__s38417     13   14    22.22     1.09    7.37    7.36     7.14%\n",
      "EArch__s38584     10   12    21.82     0.73    6.53    6.53    16.67%\n",
      "EArch__seq        12   14    10.81     0.33    5.23    5.23    14.29%\n",
      "EArch__spla       14   16    20.40     1.09    6.94    6.94    12.50%\n",
      "EArch__tseng      10   11    11.53     0.14    6.52    6.52     9.09%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "path = \"/mnt/e/benchmarks/Outputs/route_metrics/\"\n",
    "all_files = glob.glob(os.path.join(path, \"EArch*gnn*.csv\"))\n",
    "results = dict()\n",
    "results['gnn'] = dict()\n",
    "results['reg'] = dict()\n",
    "gnn_results = dict()\n",
    "reg_results = dict()\n",
    "for gnn_metric in all_files:\n",
    "    lf = gnn_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__gnn__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(gnn_metric,index_col=None,header=0)\n",
    "    \n",
    "    gnn_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['gnn'] = gnn_results\n",
    "# print(results)\n",
    "reg_results = dict()\n",
    "all_files = glob.glob(os.path.join(path, \"EArch*reg*.csv\"))\n",
    "for reg_metric in all_files:\n",
    "    lf = reg_metric.split(\"/\")[-1]\n",
    "    lf = lf.split(\".\")[0]\n",
    "    name = lf.split(\"__reg__\")[0]\n",
    "    # print(name)\n",
    "    df = pd.read_csv(reg_metric,index_col=None,header=0)\n",
    "    \n",
    "    reg_results[name] = max(df['Iteration'])\n",
    "    # print(df[].head())\n",
    "results['reg'] = reg_results\n",
    "\n",
    "# print(results)\n",
    "my_df = pd.DataFrame.from_dict(results)\n",
    "# print(my_df)\n",
    "\n",
    "my_df['Reduction'] = (my_df['reg'].values - my_df['gnn'].values)/my_df['reg'].values\n",
    "print(\"Average: \", \"{:.2%}\".format(mean(my_df['Reduction'].values)))\n",
    "\n",
    "my_df['Reduction']=  pd.Series([\"{0:.2f}%\".format(val * 100) for val in my_df['Reduction']], index = my_df.index)\n",
    "\n",
    "print(my_df)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average:  13.86%\n",
      "                 gnn  reg Reduction\n",
      "EArch__alu4       13   14     7.14%\n",
      "EArch__apex2      12   15    20.00%\n",
      "EArch__apex4      13   15    13.33%\n",
      "EArch__bigkey     10   11     9.09%\n",
      "EArch__clma       14   15     6.67%\n",
      "EArch__des        12   13     7.69%\n",
      "EArch__diffeq     12   14    14.29%\n",
      "EArch__dsip       10   12    16.67%\n",
      "EArch__elliptic   12   13     7.69%\n",
      "EArch__ex1010     13   16    18.75%\n",
      "EArch__ex5p       12   16    25.00%\n",
      "EArch__frisc      13   13     0.00%\n",
      "EArch__misex3     13   15    13.33%\n",
      "EArch__pdc        13   17    23.53%\n",
      "EArch__s298       11   14    21.43%\n",
      "EArch__s38417     11   14    21.43%\n",
      "EArch__s38584     12   12     0.00%\n",
      "EArch__seq        12   14    14.29%\n",
      "EArch__spla       13   16    18.75%\n",
      "EArch__tseng       9   11    18.18%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}